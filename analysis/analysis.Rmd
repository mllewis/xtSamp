---
output: html_document
---
<h2>  Xu and Tenenbaum 2007b Replication </h2>
<h3> Supplementary Information </h3>

***
***

**TABLE OF CONTENTS**<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(1) Original Xu and Tenenabum (2007b)](#o)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(2) Exp. 1 - online](#t1)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(3) Exp. 2 - online](#t2)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(4) Exp. 3 - in person](#l1)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(5) Exp. 4 - online](#t3)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(6) Exp. 5 - online](#t4)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(7) All](#all)** <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**[(8) Power Analysis for Exp. 5](#power5)** <br/>


This document was created from an R Markdown file. The R Markdown file can be found <a href="https://github.com/mllewis/xtSamp/blob/master/analysis/analysis.Rmd" target="_blank"> here</a>. All analyses and plots can be reproduced from the <a href="https://github.com/mllewis/xtSamp/tree/master/data" target="_blank">raw data</a> with the code in this file. Experiments conducted online can be viewed 
 <a href="https://mllewis.github.io/projects/xtSamp/xtSampindex.html" target="_blank">here</a>.

***
***

```{r setup, include = F}

rm(list = ls())

# load packages
library(knitr)
library(ggplot2)
library(plyr)
library(dplyr)
library(pwr)
library(metafor)
library(compute.es)
library(langcog)
library(tidyr)

# set graphical parameters
fs = 18
ts = 18

# define helper functions
theme_set(theme_bw())
themeML = theme(text = element_text(size = fs),
                plot.title = element_text(size = ts, face = "bold"),
                plot.background = element_blank(),
                panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.border = element_blank(),
                axis.line = element_line(color = 'black')) 

get_bootstrapped_props <- function(df, conditionName, expName){
  
  names(df)[which(names(df) == conditionName)] = "response.cat"
  
  df$response.cat = ordered(df$response.cat, levels = c("basic", "sub"))
  df$Answer.sample = ordered(df$Answer.sample, levels = c("learner", "teacher"))

  df = df %>%
    mutate(w.ans.cat.sub = as.numeric(response.cat) - 1,
           w.ans.cat.b = 1 - as.numeric(response.cat) + 1) %>%
    group_by(Answer.sample)
  
  ns = df %>% 
    group_by(response.cat, Answer.sample) %>% 
        summarise(n = n())
  
  ns_cond = df %>% 
            group_by(Answer.sample) %>% 
            summarise(n_cond = n())
  
  # get props
  props = df %>%
    multi_boot_standard(column = "w.ans.cat.b")  %>%
    mutate(response.cat = "basic") 
  props = multi_boot_standard(df, column = "w.ans.cat.sub") %>%
    mutate(response.cat = "sub") %>%
    rbind(props) %>%
    left_join(ns, by = c("response.cat", "Answer.sample")) %>%
    left_join(ns_cond, by = c("Answer.sample"))
    
  props$response.cat = as.factor(props$response.cat)
  props$response.cat = ordered(props$response.cat, levels = c("sub", "basic"))
  props$Answer.sample = ordered(props$Answer.sample, levels = c("teacher", "learner"))

  names(props)[2:4] = c("prop", "cill", "ciul")
  props$exp = expName
  
  return(props)
}

opts_chunk$set(echo = T, message = F, warning = F, error = F, cache = F)
```

There are different possible criteria  for categorizing a participant as a subordinate or basic-level generalizer. X&T find that participants respond consistently across questions as either a subordinate or a basic generalizer for each of the two trials. In contrast, we observed varied responses across questions by participants in our sample. Thus, we adopt two criteria in analyzing our data: a "strict" criteria where we only include participants if they responded consistently ("yes" or "no" to all basic-level questions and "yes" or "no" to all subordinate level questions), and a "liberal" criteria where we counted a particpant as a basic generalizer if they responded "yes" to any of the basic level questions. The results of the liberal criteria are reported in the Main Text, and the results of the strict criteria are reported in Appendix A.

```{r strict, echo = F}
# Make global analytical decisions
strict = FALSE
print(paste("Strict criteria: ", strict))
```

<a name = "o"/>
<h3> Original Xu and Tenenbaum (2007b) </h3>

X&T 2007b data - adults
```{r xt_adults}
N = 14
N_per_condition = N/2  # 2 conditions (teacher + learner)
# Note: The proportions described in the original report were obtained by aggregating across *trials* not participants (2 trials/participant). We correct for this here by taking the proportion of participants, which results in slightly different proportions than those reported in the original paper.

# make raw data
prop_sub_teacher = .928 
n_sub_teacher = round(prop_sub_teacher * N_per_condition)
n_basic_teacher = N_per_condition - n_sub_teacher 
teacher_xt_data = as.factor(c(rep("sub", n_sub_teacher),
                              rep("basic", n_basic_teacher)))

prop_sub_learner = .357
n_sub_learner = round(prop_sub_learner * N_per_condition)
n_basic_learner = N_per_condition - n_sub_learner
learner_xt_data = as.factor(c(rep("sub", n_sub_learner), 
                              rep("basic", n_basic_learner)))

xt_data.adults = data.frame(response = c(as.character(teacher_xt_data),
                                       as.character(learner_xt_data)))
xt_data.adults$Answer.sample[1:N_per_condition] = "teacher"
xt_data.adults$Answer.sample[(N_per_condition + 1):
                              (N_per_condition * 2)] = "learner"

# get props
xt.a.props = get_bootstrapped_props(xt_data.adults, "response", "X&T (2007b) adults")
```

X&T 2007b data - children
```{r xt_children}
N = 24
N_per_condition = N/2 # 2 conditions

# make raw data
prop_sub_teacher = .71
n_sub_teacher = round(prop_sub_teacher * N_per_condition)
n_basic_teacher = N_per_condition - n_sub_teacher 
teacher_xt_data = as.factor(c(rep("sub", n_sub_teacher),
                              rep("basic", n_basic_teacher)))

prop_sub_learner = .29
n_sub_learner = round(prop_sub_learner * N_per_condition)
n_basic_learner = N_per_condition - n_sub_learner
learner_xt_data = as.factor(c(rep("sub", n_sub_learner), 
                              rep("basic", n_basic_learner)))

xt_data.children = data.frame(response = c(as.character(teacher_xt_data),
                                       as.character(learner_xt_data)))
xt_data.children$Answer.sample[1:N_per_condition] = "teacher"
xt_data.children$Answer.sample[(N_per_condition + 1):
                               (N_per_condition * 2)] = "learner"

# get props
xt.c.props = get_bootstrapped_props(xt_data.children,
                                    "response", "X&T (2007b) children")
```


```{r, echo = F, width = 13}
xt = rbind(xt.c.props, xt.a.props)

# re-order levels so consistent with other exps
xt$Answer.sample <- ordered(xt$Answer.sample, 
                    levels = c("teacher", "learner"))

ggplot(xt, aes(x = response.cat, y = prop, fill = Answer.sample)) +
  facet_grid(. ~ exp) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1") +
  ggtitle("Original Xu and Tenenbaum Data") +
  themeML  
```

<a name = "t1"/>
<h3> Experiment 1 </h3>

Read in data and pre-process.
```{r exp1}
t1 = read.csv("../data/anonymized/turk_replication_1_A.csv")

# make factors
t1$Answer.sample <- factor(t1$Answer.sample, labels=c('teacher','learner')) # sample0 = teacher, sample1 = learner
t1$Answer.label <- factor(t1$Answer.label, labels=c('nolabel','label')) # 0 = nolabel, 1 = label
t1 <- colwise(as.factor)(t1)
```

Filter.
```{r}
# get number of exclusions by category
t1.exclusion.ns = t1 %>%
              summarise(n_noLabelParticipants = length(which(Answer.label != 'label')),
                        n_repeatWorkers = length(which(duplicated(workerids))),
                        n_badTraining = length(which(Answer.click1 == "\"false\"" | 
                                                       Answer.click2 == "\"false\"")),
                        n_badGeneralize = length(which(Answer.Qwcheck != 0)),
                        n_badFilter = length(which(Answer.question1 == 'FALSE')))

t1.exclusion.ns

# subset data
t1.f = t1 %>%
       filter(Answer.label == 'label') %>% #remove nolabel participants (run 4)
       filter(!duplicated(workerids)) %>% #participants who completed multiple runs
       filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% #correct training items (learning only)
       filter(Answer.Qwcheck == 0)  %>% #check generalization question
       filter(Answer.question1 == 'TRUE') #filter question

dim(t1)[1] # total
dim(t1)[1] - t1.exclusion.ns[1,"n_noLabelParticipants"] - t1.exclusion.ns[1,"n_repeatWorkers"] # actual total
dim(t1.f)[1] # total with exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <- t1.f$Answer.Qwsmm1 == 0 & t1.f$Answer.Qwsmm2 == 0 & 
  t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1
if (strict){
  basic <- (t1.f$Answer.Qwsmm1 == 1 & t1.f$Answer.Qwsmm2 == 1) &
      t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1 
} else {
  basic <- (t1.f$Answer.Qwsmm1 == 1 | t1.f$Answer.Qwsmm2 == 1) &
       t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1 
}

t1.f$w.ans.cat <- "other"
t1.f$w.ans.cat[sub] <- "sub"
t1.f$w.ans.cat[basic] <- "basic"
t1.f$w.ans.cat = factor(t1.f$w.ans.cat, levels = c("sub", "basic", "other"))

# filter out other responses
length(which(t1.f$w.ans.cat == "other"))
t1.f = t1.f[t1.f$w.ans.cat != "other",]
t1.f$w.ans.cat = droplevels(t1.f$w.ans.cat)

# get props
t1.f.props = get_bootstrapped_props(t1.f, "w.ans.cat", "Turk #1")
```

```{r, echo = F}
t1.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #1") +
  theme(legend.position=c(.85,.8)) + 
  themeML  +
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats
```{r}
t1_tab = table(t1.f$w.ans.cat, t1.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t1_tab)
```

<a name = "t2"/>
<h3> Experiment 2 </h3>

Read in data and pre-process
```{r exp2}
t2 <- read.csv("../data/anonymized/turk_replication_2_A.csv", header = T)
t2  <- t2 [,c(-1:-19,-21:-32,-36,-41:-43,-54:-55,-56)] # remove unnecessary columns

# make factors
t2$Answer.sample <- factor(t2$Answer.sample,
                           labels = c('teacher','learner')) # sample0 = teacher, sample1 = learner
t2 <- colwise(as.factor)(t2)
```

Filter.
```{r}
# get number of exclusions by category
t2.exclusion.ns = t2 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" |
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'true' | 
                                                     Answer.question2 != 'true' | 
                                                     Answer.question3 != 'true' | 
                                                     Answer.question4 !='true')))
t2.exclusion.ns

# subset data
t2.f = t2 %>%
       filter(Answer.click1 == "\"correct\"" &
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 != 'true' | Answer.question2 != 'true' | 
               Answer.question3 == 'true' & Answer.question4 == 'true')  # take out those who missed attention check questions

dim(t2)[1] # total
dim(t2.f)[1] # total with exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
  t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
  t2.f$Answer.Qsub2 == 1 & t2.f$Answer.Qbasic1 == 0 &
  t2.f$Answer.Qbasic2 == 0 & t2.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
    t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
    t2.f$Answer.Qsub2 == 1 & t2.f$Answer.Qbasic1 == 1 &
    t2.f$Answer.Qbasic2 == 1 & t2.f$Answer.Qbasic3 == 1 
} else {
  basic <- t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
    t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
    t2.f$Answer.Qsub2 == 1 & (t2.f$Answer.Qbasic1 == 1 |
    t2.f$Answer.Qbasic2 == 1 | t2.f$Answer.Qbasic3 == 1)
}

t2.f$w.ans.cat <- "other"
t2.f$w.ans.cat[sub] <- "sub"
t2.f$w.ans.cat[basic] <- "basic"
t2.f$w.ans.cat = factor(t2.f$w.ans.cat, levels = c("sub", "basic", "other"))

# filter out "other" responses
length(which(t2.f$w.ans.cat == "other"))
t2.f = t2.f[t2.f$w.ans.cat != "other",]
t2.f$w.ans.cat = droplevels(t2.f$w.ans.cat)

# get props
t2.f.props = get_bootstrapped_props(t2.f, "w.ans.cat", "Turk #2")
```

```{r, echo = F}
t2.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #2") +
  themeML + 
  theme(legend.position = c(.85, .8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats 
```{r}
t2_tab = table(t2.f$w.ans.cat, t2.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t2_tab)
```

<a name="l1"/>
<h3> Experiment 3 - In Person Replication </h3>

```{r exp3}
l1 <- read.csv("../data/anonymized/inlab_replication.csv")

# make factors
l1 <- colwise(as.factor)(l1)
names(l1)[names(l1) == "sample"] = "Answer.sample"
```

Filter.
```{r}
l1.exclusion.ns = l1 %>%
                  summarise(n_badTraining = length(
                    which(t2_a == 0 | t3_a == 0 |t2_b == 0 | t2_b == 0)))
l1.exclusion.ns

# subset data to those with correct training
l1.f = l1 %>%
       filter(t2_a == 1 & t3_a == 1 & t2_b == 1 & t2_b == 1)

dim(l1)[1] # total
dim(l1.f)[1] # total with exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <- l1.f$basic1_a == 0 & l1.f$basic2_a == 0 & 
       l1.f$basic1_b == 0 & l1.f$basic2_b == 0 & 
       (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
          l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
if (strict){
    basic <- (l1.f$basic1_a == 1 & l1.f$basic2_a == 1 &
            l1.f$basic1_b == 1 & l1.f$basic2_b == 1) & 
           (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
              l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
  
} else {
  basic <- (l1.f$basic1_a == 1 | l1.f$basic2_a == 1 | 
            l1.f$basic1_b == 1 | l1.f$basic2_b == 1) & 
           (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
              l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
}

l1.f$w.ans.cat <- "other"
l1.f$w.ans.cat[sub] <- "sub"
l1.f$w.ans.cat[basic] <- "basic"
l1.f$w.ans.cat <- factor(l1.f$w.ans.cat, c("sub","basic","other"))

# filter out "other"" responses
length(which(l1.f$w.ans.cat  == "other"))
l1.f = l1.f[l1.f$w.ans.cat != "other",]
l1.f$w.ans.cat = droplevels(l1.f$w.ans.cat)

# get props
l1.f.props = get_bootstrapped_props(l1.f, "w.ans.cat", "In person")
```

```{r, echo = F}
l1.f.props %>%
  ggplot(aes(x=response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin=cill, ymax=ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("In person") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats
```{r}
l1_tab = table(l1.f$w.ans.cat, l1.f$sample)[c("sub", "basic"),]
chisq.test(l1_tab)
```

<a name = "t3"/>
<h3> Experiment 4 - Turk Replication #3 </h3>

Read in data and pre-process
```{r exp4}
t3 <- read.csv("../data/anonymized/turk_replication_3_A.csv")

# make factors
t3$Answer.sample <- factor(t3$Answer.sample, 
                           labels=c('teacher','learner')) # sample0 = teacher, sample1 = learner
t3 <- colwise(as.factor)(t3)
```

Filter.
```{r}
t3.exclusion.ns = t3 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" | 
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'TRUE' | Answer.question2 != 'TRUE'| 
                                Answer.question3 != 'TRUE' | Answer.question4 != 'TRUE')))
t3.exclusion.ns

# subset data
t3.f = t3 %>%
      filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 == 'TRUE' & Answer.question2 == 'TRUE' & 
            Answer.question3 == 'TRUE' & Answer.question4 == 'TRUE') # take out those who missed filter question

dim(t3)[1] # total
dim(t3.f)[1] # total with exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
    t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
    t3.f$Answer.Qsub2 == 1 & t3.f$Answer.Qbasic1 == 0 &
    t3.f$Answer.Qbasic2 == 0 & t3.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
    t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
    t3.f$Answer.Qsub2 == 1 & t3.f$Answer.Qbasic1 == 1 &
    t3.f$Answer.Qbasic2 == 1 & t3.f$Answer.Qbasic3 == 1 
} else {
  basic <- t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
      t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
      t3.f$Answer.Qsub2 == 1 & (t3.f$Answer.Qbasic1 == 1 |
      t3.f$Answer.Qbasic2 == 1 | t3.f$Answer.Qbasic3 == 1)
}

t3.f$w.ans.cat <- "other"
t3.f$w.ans.cat[sub] <- "sub"
t3.f$w.ans.cat[basic] <- "basic"
t3.f$w.ans.cat = factor(t3.f$w.ans.cat, levels = c("sub", "basic", "other"))

# filter out "other"" responses
length(which(t3.f$w.ans.cat == "other"))
t3.f = t3.f[t3.f$w.ans.cat != "other",]
t3.f$w.ans.cat = droplevels(t3.f$w.ans.cat)

# get props
t3.f.props = get_bootstrapped_props(t3.f, "w.ans.cat", "Turk #3")
```

```{r, echo = F}
t3.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), 
                 position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #3") +
  themeML + 
  theme(legend.position = c(.85, .8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats
```{r}
t3_tab = table(t3.f$w.ans.cat, t3.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t3_tab)
```

<a name = "t4"/>
<h3> Experiment 5 - Turk Replication #4 </h3>

Read in data and pre-process
```{r exp5}
t4 <- read.csv("../data/anonymized/turk_replication_4_A.csv")

# make factors
t4$Answer.sample <- factor(t4$Answer.sample, 
                           labels = c('teacher','learner')) # sample0 = teacher, sample1 = learner
t4 <- colwise(as.factor)(t4)
```

Filter.
```{r}
t4.exclusion.ns = t4 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" | 
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'TRUE' | Answer.question2 !='TRUE'| 
                                Answer.question3 != 'TRUE' | Answer.question4 !='TRUE')))
t4.exclusion.ns

# subset data
t4.f = t4 %>%
      filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 == 'TRUE' & Answer.question2 == 'TRUE' & 
            Answer.question3 == 'TRUE' & Answer.question4 == 'TRUE')# take out those who missed filter question

dim(t4)[1] # total
dim(t4.f)[1] # total with exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
    t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
    t4.f$Answer.Qsub2 == 1 & t4.f$Answer.Qbasic1 == 0 &
    t4.f$Answer.Qbasic2 == 0 & t4.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
    t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
    t4.f$Answer.Qsub2 == 1 & t4.f$Answer.Qbasic1 == 1 &
    t4.f$Answer.Qbasic2 == 1 & t4.f$Answer.Qbasic3 == 1 
} else {
  basic <- t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
      t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
      t4.f$Answer.Qsub2 == 1 & (t4.f$Answer.Qbasic1 == 1 |
      t4.f$Answer.Qbasic2 == 1 | t4.f$Answer.Qbasic3 == 1)
}

t4.f$w.ans.cat <- "other"
t4.f$w.ans.cat[sub] <- "sub"
t4.f$w.ans.cat[basic] <- "basic"
t4.f$w.ans.cat = factor(t4.f$w.ans.cat, 
                        levels = c("sub", "basic", "other"))

# filter out "other"" responses
length(which(t4.f$w.ans.cat == "other"))
t4.f = t4.f[t4.f$w.ans.cat != "other",]
t4.f$w.ans.cat = droplevels(t4.f$w.ans.cat)

# get props
t4.f.props = get_bootstrapped_props(t4.f, "w.ans.cat", "Turk #4")
```

```{r, echo = F}
t4.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), 
                 position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #4") +
  themeML + 
  theme(legend.position = c(.85,.8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats
```{r}
t4_tab = table(t4.f$w.ans.cat, t4.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t4_tab)
```

<a name = "all"/>
<h3> All experiments </h3>

All proportions
```{r all_props}
# merge together all raw data 
xt_data.adults$exp = "X&T adults"
xt_data.children$exp = "X&T children"
t1.f$exp = "Exp. 1"
t2.f$exp = "Exp. 2"
l1.f$exp = "Exp. 3"
t3.f$exp = "Exp. 4"
t4.f$exp = "Exp. 5"
xt_data.adults$w.ans.cat = xt_data.adults$response
xt_data.children$w.ans.cat = xt_data.children$response

all.data.f = rbind(xt_data.children[,c("Answer.sample", "w.ans.cat", "exp")],
                  xt_data.adults[,c("Answer.sample", "w.ans.cat", "exp")],
                   t1.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t2.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   l1.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t3.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t4.f[,c("Answer.sample", "w.ans.cat", "exp")])
all.data.f <- colwise(as.factor)(all.data.f)

# get props by experiment
all.data.f.props = all.data.f %>%
                    group_by(exp) %>%
                    do(get_bootstrapped_props(.,"w.ans.cat", .$exp[1])) 

# re-order experiments
all.data.f.props$exp = factor(all.data.f.props$exp,
                           levels(all.data.f.props$exp)[c(7, 6, 1:5)]) 
```

```{r, fig.width = 12, echo = F}
all.data.f.props$response.cat  = revalue(all.data.f.props$response.cat,
                                         c("sub" = "sub."))

#pdf("../writeup/figures/FIG_2.pdf", height = 4, width = 12)
all.data.f.props %>%
  ggplot(aes(x = response.cat, y = prop, 
                             fill = Answer.sample)) +
  geom_bar(stat = "identity", 
           position = position_dodge()) +
  facet_grid(. ~ exp) +
  geom_rect(data = all.data.f.props[21:28,],
            fill = "gray", 
            xmin = -Inf, xmax = Inf, ymin = -Inf,
            ymax = Inf, alpha = 0.07) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0, 1) +
  ylab("Prop. Participants") +
  xlab("Generalization Pattern") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", 
                    palette = "Set1") 
#dev.off()
```

All effect sizes
```{r all_es}
# spread props and n_cond
all.data.f.props.basic = all.data.f.props %>%
                        filter(response.cat == "basic") %>%
                        select(-cill, -ciul, -response.cat, -prop, -n) %>%
                        spread(Answer.sample, n_cond, fill = F) %>%
                        rename(teacher_n = teacher, learner_n = learner)

all.data.f.props.basic = all.data.f.props  %>% 
                        filter(response.cat == "basic") %>%
                        select(-cill, -ciul, -response.cat,
                               -n_cond, -n) %>%
                        spread(Answer.sample, prop, fill = F) %>%
                        rename(teacher_prop = teacher,
                               learner_prop = learner) %>%
                        left_join(all.data.f.props.basic)

# get all effect sizes (compute.es package)
all.es = propes(all.data.f.props.basic$learner_prop, 
           all.data.f.props.basic$teacher_prop, 
           all.data.f.props.basic$learner_n,
           all.data.f.props.basic$teacher_n,
           verbose = F)

all.es$exp = all.data.f.props.basic$exp # add exp ids
```

```{r}
# fixed effects (metafor package)
fixed.effects.d = rma(d, var.d, data = all.es, method = "FE")
fixed.effects.d

# random effects
random.effects.d = rma(d, var.d, data = all.es)
random.effects.d
```

```{r, echo = F}
#pdf("../writeup/figures/FIG_3.pdf", height = 5, width = 8)
par(cex = 1, font = 1)
forest(random.effects.d, 
       slab = all.es$exp,
       mlab = "All", 
       xlab = "Cohen's d")
par(font = 2)
text(-3.6, 8.55, "Experiment")
text(5.8, 8.55, "Cohen's d [95% CI]")

addpoly(random.effects.d, row = -1, cex = .75, 
        annotate = F,  col = "red", mlab = "", efac = 2)
#dev.off()
```

<a name = "power5"/>
<h3> Power analysis for Exp. 5 </h3>
<h4> ES based on X&T adults and Exp 1-4  </h4>

```{r exp5_power}
# Note: Here we use r to estimate effect size, which is formally equivalent to phi. Phi is formally equivalent to omega for 2 x 2 tables, which is the effect size estimator used in the pwr.chisq.test function. Elsewhere, we work with effect sizes using d. 

# fixed effects
fixed.effects = rma(r, var.r, data = all.es[2:6,], method = "FE")
power.analysis = pwr.chisq.test(w = fixed.effects$b,
                                df = 1, 
                                sig.level = 0.05,
                                power = .95)
power.analysis
print(paste("N for .95 power (fixed effects):",
            power.analysis$N))
print(paste("Extra: ", .35 * power.analysis$N))

# random effects
random.effects = rma(r, var.r, data = all.es[2:6,])
power.analysis = pwr.chisq.test(w = random.effects$b, 
                                df = 1, 
                                sig.level = 0.05, 
                                power = .95)
power.analysis
print(paste("N for .95 power (random effects):",
            power.analysis$N))
print(paste("Extra: ", .35 * power.analysis$N))
```

Thus, by the most conservative estimate (criteria: strict = T; fixed effect), we need a N of 363 to achieve 95% power. With approximately 35% data loss, this means we need to run an extra 127 to achieve this power. This is approximately 500 participants. 