---
title: Xu and Tenenbaum 2007b Replication- Supplementary Information
author: "Molly Lewis and Michael C. Frank"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
---
  
***
***

This document was created from an R Markdown file. The R Markdown file can be found <a href="https://github.com/mllewis/xtSamp/blob/master/analysis/analysis.Rmd" target="_blank"> here</a>. All analyses and plots can be reproduced from the <a href="https://github.com/mllewis/xtSamp/tree/master/data" target="_blank">raw data</a> with the code in this file. Experiments conducted online can be viewed 
 <a href="https://mllewis.github.io/projects/xtSamp/xtSampindex.html" target="_blank">here</a>.

***
***

```{r setup, include = F}

rm(list = ls())

# load packages
library(knitr)
library(ggplot2)
library(plyr)
library(dplyr)
library(pwr)
library(metafor)
library(compute.es)
library(langcog)
library(tidyr)
library(broom)
library(reshape2)

# set graphical parameters
fs = 18
ts = 18

# define helper functions
theme_set(theme_bw())
themeML = theme(text = element_text(size = fs),
                plot.title = element_text(size = ts, face = "bold"),
                plot.background = element_blank(),
                panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.border = element_blank(),
                axis.line = element_line(color = 'black')) 

get_bootstrapped_props <- function(df, conditionName, expName){
  
  names(df)[which(names(df) == conditionName)] = "response.cat"
  
  df$response.cat = ordered(df$response.cat, levels = c("basic", "sub"))
  df$Answer.sample = ordered(df$Answer.sample, levels = c("learner", "teacher"))

  df = df %>%
    mutate(w.ans.cat.sub = as.numeric(response.cat) - 1,
           w.ans.cat.b = 1 - as.numeric(response.cat) + 1) %>%
    group_by(Answer.sample)
  
  ns = df %>% 
    group_by(response.cat, Answer.sample) %>% 
        summarise(n = n())
  
  ns_cond = df %>% 
            group_by(Answer.sample) %>% 
            summarise(n_cond = n())
  
  # get props
  props = df %>%
    multi_boot_standard(column = "w.ans.cat.b")  %>%
    mutate(response.cat = "basic") 
  props = multi_boot_standard(df, column = "w.ans.cat.sub") %>%
    mutate(response.cat = "sub") %>%
    rbind(props) %>%
    left_join(ns, by = c("response.cat", "Answer.sample")) %>%
    left_join(ns_cond, by = c("Answer.sample"))
    
  props$response.cat = as.factor(props$response.cat)
  props$response.cat = ordered(props$response.cat, levels = c("sub", "basic"))
  props$Answer.sample = ordered(props$Answer.sample, levels = c("teacher", "learner"))

  names(props)[2:4] = c("prop", "cill", "ciul")
  props$exp = expName
  
  return(props)
}

opts_chunk$set(echo = T, message = F, warning = F, error = F, cache = T)
```

There are different possible criteria  for categorizing a participant as a subordinate or basic-level generalizer. X&T find that participants respond consistently across questions as either a subordinate or a basic generalizer for each of the two trials. In contrast, we observed varied responses across questions by participants in our sample. Thus, we adopt two criteria in analyzing our data: a "strict" criteria where we only include participants if they responded consistently ("yes" or "no" to all basic-level questions and "yes" or "no" to all subordinate level questions), and a "liberal" criteria where we counted a particpant as a basic generalizer if they responded "yes" to any of the basic level questions. The results of the liberal criteria are reported in the Main Text, and the results of the strict criteria are reported in Appendix A.

```{r strict, echo = F}
# Make global analytical decisions
strict = FALSE
print(paste("Strict criteria: ", strict))
```

##  Original Xu and Tenenbaum (2007b) 

X&T 2007b data - adults
```{r xt_adults}
N = 14
N_per_condition = N/2  # 2 conditions (teacher + learner)
# Note: The proportions described in the original report were obtained by aggregating across *trials* not participants (2 trials/participant). We correct for this here by taking the proportion of participants, which results in slightly different proportions than those reported in the original paper.

# make raw data
prop_sub_teacher = .928 
n_sub_teacher = round(prop_sub_teacher * N_per_condition)
n_basic_teacher = N_per_condition - n_sub_teacher 
teacher_xt_data = as.factor(c(rep("sub", n_sub_teacher),
                              rep("basic", n_basic_teacher)))

prop_sub_learner = .357
n_sub_learner = round(prop_sub_learner * N_per_condition)
n_basic_learner = N_per_condition - n_sub_learner
learner_xt_data = as.factor(c(rep("sub", n_sub_learner), 
                              rep("basic", n_basic_learner)))

xt_data.adults = data.frame(response = c(as.character(teacher_xt_data),
                                       as.character(learner_xt_data)))
xt_data.adults$Answer.sample[1:N_per_condition] = "teacher"
xt_data.adults$Answer.sample[(N_per_condition + 1):
                              (N_per_condition * 2)] = "learner"
```

Get props.
```{r}
# get props
xt.a.props = get_bootstrapped_props(xt_data.adults, "response",
                                    "X&T (2007b) adults")
```

X&T 2007b data - children
```{r xt_children}
N = 24
N_per_condition = N/2 # 2 conditions

# make raw data
prop_sub_teacher = .71
n_sub_teacher = round(prop_sub_teacher * N_per_condition)
n_basic_teacher = N_per_condition - n_sub_teacher 
teacher_xt_data = as.factor(c(rep("sub", n_sub_teacher),
                              rep("basic", n_basic_teacher)))

prop_sub_learner = .29
n_sub_learner = round(prop_sub_learner * N_per_condition)
n_basic_learner = N_per_condition - n_sub_learner
learner_xt_data = as.factor(c(rep("sub", n_sub_learner), 
                              rep("basic", n_basic_learner)))

xt_data.children = data.frame(response = c(as.character(teacher_xt_data),
                                       as.character(learner_xt_data)))
xt_data.children$Answer.sample[1:N_per_condition] = "teacher"
xt_data.children$Answer.sample[(N_per_condition + 1):
                               (N_per_condition * 2)] = "learner"
```

Get props.
```{r}
xt.c.props = get_bootstrapped_props(xt_data.children,
                                    "response", "X&T (2007b) children")
```

```{r, echo = F, width = 13}
xt = rbind(xt.c.props, xt.a.props)

# re-order levels so consistent with other exps
xt$Answer.sample <- ordered(xt$Answer.sample, 
                    levels = c("teacher", "learner"))

ggplot(xt, aes(x = response.cat, y = prop, fill = Answer.sample)) +
  facet_grid(. ~ exp) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1") +
  ggtitle("Original Xu and Tenenbaum Data") +
  themeML  
```

Stats.
```{r}
xta_tab = table(xt_data.adults$Answer.sample, xt_data.adults$response)
chisq.test(xta_tab)

xtc_tab = table(xt_data.children$Answer.sample, xt_data.children$response)
chisq.test(xtc_tab)
```

## Experiment 1 - Turk Replication #1

Read in data and pre-process.
```{r exp1}
t1 = read.csv("../data/anonymized/turk_replication_1_A.csv")

# make factors
t1$Answer.sample <- factor(t1$Answer.sample, labels=c('teacher','learner')) # sample0 = teacher, sample1 = learner
t1$Answer.label <- factor(t1$Answer.label, labels=c('nolabel','label')) # 0 = nolabel, 1 = label
t1 <- colwise(as.factor)(t1)
```

Filter.
```{r}
dim(t1)[1] # total

# get number of exclusions by category
t1.exclusion.ns = t1 %>%
              summarise(n_noLabelParticipants = length(which(Answer.label != 'label')),
                        n_repeatWorkers = length(which(duplicated(workerids))),
                        n_badTraining = length(which(Answer.click1 == "\"false\"" | 
                                                       Answer.click2 == "\"false\"")),
                        n_badGeneralize = length(which(Answer.Qwcheck != 0)),
                        n_badFilter = length(which(Answer.question1 == 'FALSE')))

t1.exclusion.ns
dim(t1)[1] - t1.exclusion.ns[1,"n_noLabelParticipants"] - t1.exclusion.ns[1,"n_repeatWorkers"] # actual total

# subset data
t1.f = t1 %>%
       filter(Answer.label == 'label') %>% #remove nolabel participants (run 4)
       filter(!duplicated(workerids)) %>% #participants who completed multiple runs
       filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% #correct training items (learning only)
       filter(Answer.Qwcheck == 0)  %>% #check generalization question
       filter(Answer.question1 == 'TRUE') #filter question


dim(t1.f)[1] # total before other exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <- t1.f$Answer.Qwsmm1 == 0 & t1.f$Answer.Qwsmm2 == 0 & 
  t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1
if (strict){
  basic <- (t1.f$Answer.Qwsmm1 == 1 & t1.f$Answer.Qwsmm2 == 1) &
      t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1 
} else {
  basic <- (t1.f$Answer.Qwsmm1 == 1 | t1.f$Answer.Qwsmm2 == 1) &
       t1.f$Answer.Qwsm1 == 1 & t1.f$Answer.Qwsm2 == 1 
}

t1.f$w.ans.cat <- "other"
t1.f$w.ans.cat[sub] <- "sub"
t1.f$w.ans.cat[basic] <- "basic"
t1.f$w.ans.cat = factor(t1.f$w.ans.cat, levels = c("sub", "basic", "other"))

# get other responeses
others.t1 = filter(t1.f, w.ans.cat == "other")
dim(others.t1)[1]

# filter out other responses
t1.f = t1.f[t1.f$w.ans.cat != "other",]
t1.f$w.ans.cat = droplevels(t1.f$w.ans.cat)

# final N:
length(t1.f$Answer.sample)
summary(t1.f$Answer.sample)
```

Get props.
```{r}
t1.f.props = get_bootstrapped_props(t1.f, "w.ans.cat",
                                    "Turk #1")
```

```{r, echo = F}
t1.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #1") +
  theme(legend.position=c(.85,.8)) + 
  themeML  +
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats.
```{r}
t1_tab = table(t1.f$w.ans.cat, t1.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t1_tab)
```


## Experiment 2 - Turk Replication #2

Read in data and pre-process
```{r exp2}
t2 <- read.csv("../data/anonymized/turk_replication_2_A.csv", header = T)
t2  <- t2 [,c(-1:-19,-21:-32,-36,-41:-43,-54:-55,-56)] # remove unnecessary columns

# make factors
t2$Answer.sample <- factor(t2$Answer.sample,
                           labels = c('teacher','learner')) # sample0 = teacher, sample1 = learner
t2 <- colwise(as.factor)(t2)
```

Filter.
```{r}
# get number of exclusions by category
t2.exclusion.ns = t2 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" |
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'true' | 
                                                     Answer.question2 != 'true' | 
                                                     Answer.question3 != 'true' | 
                                                     Answer.question4 !='true')))
t2.exclusion.ns

# subset data
t2.f = t2 %>%
       filter(Answer.click1 == "\"correct\"" &
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 != 'true' | Answer.question2 != 'true' | 
               Answer.question3 == 'true' & Answer.question4 == 'true')  # take out those who missed attention check questions


dim(t2.f)[1] # total before "other" exlcusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
  t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
  t2.f$Answer.Qsub2 == 1 & t2.f$Answer.Qbasic1 == 0 &
  t2.f$Answer.Qbasic2 == 0 & t2.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
    t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
    t2.f$Answer.Qsub2 == 1 & t2.f$Answer.Qbasic1 == 1 &
    t2.f$Answer.Qbasic2 == 1 & t2.f$Answer.Qbasic3 == 1 
} else {
  basic <- t2.f$Answer.Qproper1 == 1 & t2.f$Answer.Qproper2 == 1 & 
    t2.f$Answer.Qproper3 == 1 & t2.f$Answer.Qsub1 == 1 &
    t2.f$Answer.Qsub2 == 1 & (t2.f$Answer.Qbasic1 == 1 |
    t2.f$Answer.Qbasic2 == 1 | t2.f$Answer.Qbasic3 == 1)
}

t2.f$w.ans.cat <- "other"
t2.f$w.ans.cat[sub] <- "sub"
t2.f$w.ans.cat[basic] <- "basic"
t2.f$w.ans.cat = factor(t2.f$w.ans.cat, levels = c("sub", "basic", "other"))

# get other responeses
others.t2 = filter(t2.f, w.ans.cat == "other")
dim(others.t2)[1]

# filter out other responses
t2.f = t2.f[t2.f$w.ans.cat != "other",]
t2.f$w.ans.cat = droplevels(t2.f$w.ans.cat)

# final N:
length(t2.f$Answer.sample)
summary(t2.f$Answer.sample)
```

Get props.
```{r}
t2.f.props = get_bootstrapped_props(t2.f, "w.ans.cat",
                                    "Turk #2")
```

```{r, echo = F}
t2.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #2") +
  themeML + 
  theme(legend.position = c(.85, .8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats.
```{r}
t2_tab = table(t2.f$w.ans.cat, t2.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t2_tab)
```

## Experiment 3 - In Person Replication 

```{r exp3}
l1 <- read.csv("../data/anonymized/inlab_replication.csv")

# make factors
l1 <- colwise(as.factor)(l1)
names(l1)[names(l1) == "sample"] = "Answer.sample"
```

Filter.
```{r}
l1.exclusion.ns = l1 %>%
                  summarise(n_badTraining = length(
                    which(t2_a == 0 | t3_a == 0 |t2_b == 0 | t2_b == 0)))
l1.exclusion.ns

# subset data to those with correct training
l1.f = l1 %>%
       filter(t2_a == 1 & t3_a == 1 & t2_b == 1 & t2_b == 1)

dim(l1)[1] # total
dim(l1.f)[1] # total before "other" exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <- l1.f$basic1_a == 0 & l1.f$basic2_a == 0 & 
       l1.f$basic1_b == 0 & l1.f$basic2_b == 0 & 
       (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
          l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
if (strict){
    basic <- (l1.f$basic1_a == 1 & l1.f$basic2_a == 1 &
            l1.f$basic1_b == 1 & l1.f$basic2_b == 1) & 
           (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
              l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
  
} else {
  basic <- (l1.f$basic1_a == 1 | l1.f$basic2_a == 1 | 
            l1.f$basic1_b == 1 | l1.f$basic2_b == 1) & 
           (l1.f$sub1_a == 1 & l1.f$sub2_a == 1 & 
              l1.f$sub1_b == 1 & l1.f$sub2_b == 1)
}

l1.f$w.ans.cat <- "other"
l1.f$w.ans.cat[sub] <- "sub"
l1.f$w.ans.cat[basic] <- "basic"
l1.f$w.ans.cat <- factor(l1.f$w.ans.cat, c("sub","basic","other"))

# get other responeses
others.l1 = filter(l1.f, w.ans.cat == "other")
dim(others.l1)[1]

# filter out other responses
l1.f = l1.f[l1.f$w.ans.cat != "other",]
l1.f$w.ans.cat = droplevels(l1.f$w.ans.cat)

# final N:
length(l1.f$Answer.sample)
summary(l1.f$Answer.sample)
```

Get props.
```{r}
l1.f.props = get_bootstrapped_props(l1.f, "w.ans.cat",
                                    "In person")
```

```{r, echo = F}
l1.f.props %>%
  ggplot(aes(x=response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin=cill, ymax=ciul), position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("In person") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats.
```{r}
l1_tab = table(l1.f$w.ans.cat, l1.f$sample)[c("sub", "basic"),]
chisq.test(l1_tab)
```

## Experiment 4 - Turk Replication #3

Read in data and pre-process
```{r exp4}
t3 <- read.csv("../data/anonymized/turk_replication_3_A.csv")

# make factors
t3$Answer.sample <- factor(t3$Answer.sample, 
                           labels=c('teacher','learner')) # sample0 = teacher, sample1 = learner
t3 <- colwise(as.factor)(t3)
```

Filter.
```{r}
t3.exclusion.ns = t3 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" | 
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'TRUE' | Answer.question2 != 'TRUE'| 
                                Answer.question3 != 'TRUE' | Answer.question4 != 'TRUE')))
t3.exclusion.ns

# subset data
t3.f = t3 %>%
      filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 == 'TRUE' & Answer.question2 == 'TRUE' & 
            Answer.question3 == 'TRUE' & Answer.question4 == 'TRUE') # take out those who missed filter question

dim(t3)[1] # total
dim(t3.f)[1] # total before "other" exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
    t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
    t3.f$Answer.Qsub2 == 1 & t3.f$Answer.Qbasic1 == 0 &
    t3.f$Answer.Qbasic2 == 0 & t3.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
    t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
    t3.f$Answer.Qsub2 == 1 & t3.f$Answer.Qbasic1 == 1 &
    t3.f$Answer.Qbasic2 == 1 & t3.f$Answer.Qbasic3 == 1 
} else {
  basic <- t3.f$Answer.Qproper1 == 1 & t3.f$Answer.Qproper2 == 1 & 
      t3.f$Answer.Qproper3 == 1 & t3.f$Answer.Qsub1 == 1 &
      t3.f$Answer.Qsub2 == 1 & (t3.f$Answer.Qbasic1 == 1 |
      t3.f$Answer.Qbasic2 == 1 | t3.f$Answer.Qbasic3 == 1)
}

t3.f$w.ans.cat <- "other"
t3.f$w.ans.cat[sub] <- "sub"
t3.f$w.ans.cat[basic] <- "basic"
t3.f$w.ans.cat = factor(t3.f$w.ans.cat, levels = c("sub", "basic", "other"))

# get other responeses
others.t3 = filter(t3.f, w.ans.cat == "other")
dim(others.t3)[1]

# filter out other responses
t3.f = t3.f[t3.f$w.ans.cat != "other",]
t3.f$w.ans.cat = droplevels(t3.f$w.ans.cat)

# final N:
length(t3.f$Answer.sample)
summary(t3.f$Answer.sample)
```

Get props.
```{r}
t3.f.props = get_bootstrapped_props(t3.f, "w.ans.cat", 
                                    "Turk #3")
```

```{r, echo = F}
t3.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), 
                 position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #3") +
  themeML + 
  theme(legend.position = c(.85, .8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats.
```{r}
t3_tab = table(t3.f$w.ans.cat, t3.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t3_tab)
```

## Experiment 5 - Turk Replication #4 

Read in data and pre-process
```{r exp5}
t4 <- read.csv("../data/anonymized/turk_replication_4_A.csv")

# make factors
t4$Answer.sample <- factor(t4$Answer.sample, 
                           labels = c('teacher','learner')) # sample0 = teacher, sample1 = learner
t4 <- colwise(as.factor)(t4)
```

Filter.
```{r}
t4.exclusion.ns = t4 %>%
              summarise(n_badTraining = length(which(Answer.click1 != "\"correct\"" | 
                                                       Answer.click2 != "\"correct\"")),
                        n_badGeneralize = length(which(Answer.Qcheck1 != 0 | Answer.Qcheck2 != 0)),
                        n_badFilter = length(which(Answer.question1 != 'TRUE' | Answer.question2 !='TRUE'| 
                                Answer.question3 != 'TRUE' | Answer.question4 !='TRUE')))
t4.exclusion.ns

# subset data
t4.f = t4 %>%
      filter(Answer.click1 == "\"correct\"" & 
                Answer.click2 == "\"correct\"") %>% # take out those who click on wrong training items
      filter(Answer.Qcheck1 == 0 & Answer.Qcheck2 == 0) %>% # take out if missed check generalization question
      filter(Answer.question1 == 'TRUE' & Answer.question2 == 'TRUE' & 
            Answer.question3 == 'TRUE' & Answer.question4 == 'TRUE')# take out those who missed filter question

dim(t4)[1] # total
dim(t4.f)[1] # total before "other" exclusions
```

Categorize response patterns based on criterion.
```{r}
sub <-  t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
    t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
    t4.f$Answer.Qsub2 == 1 & t4.f$Answer.Qbasic1 == 0 &
    t4.f$Answer.Qbasic2 == 0 & t4.f$Answer.Qbasic3 == 0 

if (strict){
  basic <- t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
    t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
    t4.f$Answer.Qsub2 == 1 & t4.f$Answer.Qbasic1 == 1 &
    t4.f$Answer.Qbasic2 == 1 & t4.f$Answer.Qbasic3 == 1 
} else {
  basic <- t4.f$Answer.Qproper1 == 1 & t4.f$Answer.Qproper2 == 1 & 
      t4.f$Answer.Qproper3 == 1 & t4.f$Answer.Qsub1 == 1 &
      t4.f$Answer.Qsub2 == 1 & (t4.f$Answer.Qbasic1 == 1 |
      t4.f$Answer.Qbasic2 == 1 | t4.f$Answer.Qbasic3 == 1)
}

t4.f$w.ans.cat <- "other"
t4.f$w.ans.cat[sub] <- "sub"
t4.f$w.ans.cat[basic] <- "basic"
t4.f$w.ans.cat = factor(t4.f$w.ans.cat, 
                        levels = c("sub", "basic", "other"))

# filter out "other" responses
others.t4 = filter(t4.f, w.ans.cat == "other")
dim(others.t4)[1]

# filter out other responses
t4.f = t4.f[t4.f$w.ans.cat != "other",]
t4.f$w.ans.cat = droplevels(t4.f$w.ans.cat)

# final N:
length(t4.f$Answer.sample)
summary(t4.f$Answer.sample)
```

Get props.
```{r}
t4.f.props = get_bootstrapped_props(t4.f, "w.ans.cat",
                                    "Turk #4")
```

```{r, echo = F}
t4.f.props %>%
  ggplot(aes(x = response.cat, y = prop, fill = Answer.sample)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_linerange(aes(ymin = cill, ymax = ciul), 
                 position = position_dodge(.9)) +
  ylim(0,1) +
  ylab("Prop. participants") +
  xlab("Generalization pattern") +
  ggtitle("Turk Replication #4") +
  themeML + 
  theme(legend.position = c(.85,.8)) + 
  scale_fill_brewer(name = "Sampling\nCondition", palette = "Set1")
```

Stats.
```{r}
t4_tab = table(t4.f$w.ans.cat, t4.f$Answer.sample)[c("sub", "basic"),]
chisq.test(t4_tab)
```

## All experiments 

All proportions
```{r all_props}
# merge together all raw data 
xt_data.adults$exp = "X&T adults"
xt_data.children$exp = "X&T children"
t1.f$exp = "Exp. 1"
t2.f$exp = "Exp. 2"
l1.f$exp = "Exp. 3"
t3.f$exp = "Exp. 4"
t4.f$exp = "Exp. 5"
xt_data.adults$w.ans.cat = xt_data.adults$response
xt_data.children$w.ans.cat = xt_data.children$response

all.data.f = rbind(xt_data.children[,c("Answer.sample", "w.ans.cat", "exp")],
                  xt_data.adults[,c("Answer.sample", "w.ans.cat", "exp")],
                   t1.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t2.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   l1.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t3.f[,c("Answer.sample", "w.ans.cat", "exp")],
                   t4.f[,c("Answer.sample", "w.ans.cat", "exp")])
all.data.f <- colwise(as.factor)(all.data.f)

# get props by experiment
all.data.f.props = all.data.f %>%
                    group_by(exp) %>%
                    do(get_bootstrapped_props(.,"w.ans.cat", .$exp[1])) 

# re-order experiments
all.data.f.props$exp = factor(all.data.f.props$exp,
                           levels(all.data.f.props$exp)[c(7, 6, 1:5)]) 
```

```{r, fig.width = 12, echo = F}
all.data.f.props$response.cat  = revalue(all.data.f.props$response.cat,
                                         c("sub" = "sub."))

#pdf("../writeup/figures/FIG_2.pdf", height = 4, width = 12)
all.data.f.props %>%
  ggplot(aes(x = response.cat, y = prop, 
                             fill = Answer.sample)) +
  geom_bar(stat = "identity", 
           position = position_dodge()) +
  facet_grid(. ~ exp) +
  geom_rect(data = all.data.f.props[21:28,],
            fill = "gray", 
            xmin = -Inf, xmax = Inf, ymin = -Inf,
            ymax = Inf, alpha = 0.07) +
  geom_linerange(aes(ymin = cill, ymax = ciul), position = position_dodge(.9)) +
  ylim(0, 1) +
  ylab("Prop. Participants") +
  xlab("Generalization Pattern") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", 
                    palette = "Set1") 
#dev.off()
```

All effect sizes
```{r all_es}
# spread props and n_cond
all.data.f.props.basic = all.data.f.props %>%
                        filter(response.cat == "basic") %>%
                        select(-cill, -ciul, -response.cat, -prop, -n) %>%
                        spread(Answer.sample, n_cond, fill = F) %>%
                        rename(teacher_n = teacher, learner_n = learner)

all.data.f.props.basic = all.data.f.props  %>% 
                        filter(response.cat == "basic") %>%
                        select(-cill, -ciul, -response.cat,
                               -n_cond, -n) %>%
                        spread(Answer.sample, prop, fill = F) %>%
                        rename(teacher_prop = teacher,
                               learner_prop = learner) %>%
                        left_join(all.data.f.props.basic)

# get all effect sizes (compute.es package)
all.es = propes(all.data.f.props.basic$learner_prop, 
           all.data.f.props.basic$teacher_prop, 
           all.data.f.props.basic$learner_n,
           all.data.f.props.basic$teacher_n,
           verbose = F)

all.es$exp = all.data.f.props.basic$exp # add exp ids
```

```{r}
# fixed effects (metafor package)
fixed.effects.d = rma(d, var.d, data = all.es, method = "FE")
fixed.effects.d

# random effects
random.effects.d = rma(d, var.d, data = all.es)
random.effects.d
```

```{r, echo = F}
#pdf("../writeup/figures/FIG_3.pdf", height = 5, width = 8)
par(cex = 1, font = 1)
forest(random.effects.d, 
       slab = all.es$exp,
       mlab = "All", 
       xlab = "Cohen's d")
par(font = 2)
text(-3.6, 8.55, "Experiment")
text(5.8, 8.55, "Cohen's d [95% CI]")

addpoly(random.effects.d, row = -1, cex = .75, 
        annotate = F,  col = "red", mlab = "", efac = 2)
#dev.off()
```

## Power analysis for Exp. 5 </h3>
ES based on X&T adults and Exp 1-4

```{r exp5_power}
# Note: Here we use r to estimate effect size, which is formally equivalent to phi. Phi is formally equivalent to omega for 2 x 2 tables, which is the effect size estimator used in the pwr.chisq.test function. Elsewhere, we work with effect sizes using d. 

# fixed effects
fixed.effects = rma(r, var.r, data = all.es[2:6,], method = "FE")
power.analysis = pwr.chisq.test(w = fixed.effects$b,
                                df = 1, 
                                sig.level = 0.05,
                                power = .95)
power.analysis
print(paste("N for .95 power (fixed effects):",
            power.analysis$N))
print(paste("Extra: ", .35 * power.analysis$N))

# random effects
random.effects = rma(r, var.r, data = all.es[2:6,])
power.analysis = pwr.chisq.test(w = random.effects$b, 
                                df = 1, 
                                sig.level = 0.05, 
                                power = .95)
power.analysis
print(paste("N for .95 power (random effects):",
            power.analysis$N))
print(paste("Extra: ", .35 * power.analysis$N))
```

Thus, by the most conservative estimate (criteria: strict = T; fixed effect), we need a N of 363 to achieve 95% power. With approximately 35% data loss, this means we need to run an extra 127 to achieve this power. This is approximately 500 participants. 

## Analyses of possible moderators 

One possible reason for the difference between our observed effect sizes and the original is the presence of moderators. There are two notable differences between our experiments and the original: the online nature of several of our experiments, and the different stimuli used in Experiments 1-3. Here we test whether these moderators are reliable. 

Person Effect
```{r person_effect}

# Welch's t-test
# s = variance
welch_t_test <- function(d1, d2, s1, s2, n1, n2){
  t = (d1 - d2)/sqrt((s1/n1) + (s2/n2))
  df = ((s1/n1) + (s2/n2))^2 / (((s1/n1)^2/(n1-1)) + ((s2/n2)^2/(n2-1)))
  p = 2*(1-pt(abs(t),df))
  results = c(t, df, p)
  names(results) = c("t", "df", "p")
  
  results
}

mod = predict(rma(d, var.d, data = all.es[3:4,], method = "FE"))
d1 = mod$pred  
n1 = (all.es[all.es$exp == "Exp. 1", "N.total"] +
        all.es[all.es$exp == "Exp. 2", "N.total"])/2
s1 = mod$se^2
d2 = all.es[all.es$exp == "Exp. 3", "d"]  
n2 = all.es[all.es$exp == "Exp. 3", "N.total"]  
s2 = all.es[all.es$exp == "Exp. 3", "var.d"]

welch_t_test(d1, d2, s1, s2, n1, n2)
```

```{r person_effect_power, eval = F}
# estimate person effect using Exp 3 vs. 1 and 2. 
min_person_effect = all.es[all.es$exp == "Exp. 3", "d"] - 
  all.es[all.es$exp == "Exp. 2", "d"] 

max_person_effect = all.es[all.es$exp == "Exp. 3", "d"] - 
  all.es[all.es$exp == "Exp. 1", "d"] 

# get sample size of experiment 4 and 5
N_4_and_5 = all.es[all.es$exp == "Exp. 4", "N.total"] + 
  all.es[all.es$exp == "Exp. 5", "N.total"] 

# do power analysis to figure out how many people would need for an additional experiment
# with an effect size difference of person effect from expeirment 4 and 5
pwr.t2n.test(d = min_person_effect, n1 = N_4_and_5, power = .8)
pwr.t2n.test(d = max_person_effect, n1 = N_4_and_5, power = .8)
```

Stimuli Effect
```{r stim_effect}
mod = predict(rma(d, var.d, data = all.es[3:4,], method = "FE"))
d1 = mod$pred  
n1 = (all.es[all.es$exp == "Exp. 1", "N.total"] +
        all.es[all.es$exp == "Exp. 2", "N.total"])/2
s1 = mod$se^2
mod2 = predict(rma(d, var.d, data = all.es[6:7,], method = "FE"))
d2 = mod2$pred  
n2 = (all.es[all.es$exp == "Exp. 4", "N.total"] +
        all.es[all.es$exp == "Exp. 5", "N.total"])/2
s2 = mod2$se^2

welch_t_test(d1, d2, s1, s2, n1, n2)
```

Testing moderators using logistic regression
Person effect
```{r}
all.data.f$exp2 = as.factor(ifelse(all.data.f$exp == "Exp. 1"|
                           all.data.f$exp == "Exp. 2", "web.badStim", 
                         ifelse( all.data.f$exp == "Exp. 3", "lab.badStim", 
                                 ifelse(all.data.f$exp == "Exp. 4"|
                           all.data.f$exp == "Exp. 5", "web.goodStim", all.data.f$exp))))

person.effect.model = glm(w.ans.cat ~ Answer.sample + exp2, 
    data = all.data.f[all.data.f$exp2 == "web.badStim" |
                        all.data.f$exp2 == "lab.badStim", ], 
    family = "binomial")
tidy(person.effect.model)


person.effect.model = glm(w.ans.cat ~ Answer.sample * exp2, 
    data = all.data.f[all.data.f$exp2 == "web.badStim" |
                        all.data.f$exp2 == "lab.badStim", ], 
    family = "binomial")
tidy(person.effect.model)
```

Stim effect
```{r}
all.data.f$exp2 = as.factor(ifelse(all.data.f$exp == "Exp. 1"|
                           all.data.f$exp == "Exp. 2", "web.badStim", 
                         ifelse( all.data.f$exp == "Exp. 3", "lab.badStim", 
                                 ifelse(all.data.f$exp == "Exp. 4"|
                           all.data.f$exp == "Exp. 5", "web.goodStim", all.data.f$exp))))

stim.effect.model = glm(w.ans.cat ~ Answer.sample + exp2, 
    data = all.data.f[all.data.f$exp2 == "web.badStim" |
                        all.data.f$exp2 == "web.goodStim", ], 
    family = "binomial")
tidy(stim.effect.model)

all.data.f$exp2 = as.factor(ifelse(all.data.f$exp == "Exp. 1"|
                           all.data.f$exp == "Exp. 2", "web.badStim", 
                         ifelse( all.data.f$exp == "Exp. 3", "lab.badStim", 
                                 ifelse(all.data.f$exp == "Exp. 4"|
                           all.data.f$exp == "Exp. 5", "web.goodStim", all.data.f$exp))))

stim.effect.model = glm(w.ans.cat ~ Answer.sample * exp2, 
    data = all.data.f[all.data.f$exp2 == "web.badStim" |
                        all.data.f$exp2 == "web.goodStim", ], 
    family = "binomial")
tidy(stim.effect.model)
```

glm power analysis
```{r exp6_power}
# estimate effect size of E6
fixed.effects.turk.goodStim = rma(d, c(.01, .01),
                                  data = all.es[6:7,], method = "FE")$b # exp 4 and 5
fixed.effects.turk.badStim = rma(d, var.r,
                                  data = all.es[3:4,], method = "FE")$b # exp 1 and 2
fixed.effects.lab.badStim = all.es[5,"d"]
personEffect = fixed.effects.lab.badStim - fixed.effects.turk.badStim 
exp6_es = (fixed.effects.lab.badStim + personEffect)[1]

# convert es E6 to proportions and then make each observation a row
# Note: I got props from just messing around with propes function using exp6_es
learner_prop_basic = .28
teacher_prop_basic = .1
learner_prop_sub = 1 - learner_prop_basic 
teacher_prop_sub = 1 - teacher_prop_basic

d.goodStim.lab.estimated = data.frame(matrix(ncol = 0, nrow = 200))
d.goodStim.lab.estimated$Answer.sample = rep("teacher",100)
d.goodStim.lab.estimated$Answer.sample[101:200] = rep("learner",100)
d.goodStim.lab.estimated$w.ans.cat = "sub"
d.goodStim.lab.estimated$w.ans.cat[1:(teacher_prop_basic*100)] = "basic"
d.goodStim.lab.estimated$w.ans.cat[101:(100+(learner_prop_basic*100))] = "basic"
d.goodStim.lab.estimated$exp = "exp6"

# E4 and E5 data with each observation a row
d.goodStim.turk = rbind(t3.f, t4.f)[,c("w.ans.cat", "Answer.sample")]
d.goodStim.turk$exp = "exp4and5"

# run power simulation
prop_sig_ps = numeric(0)
for (n in seq(5,1000,5)){
  #print(n)
  ps = numeric(0)
  
  for (s in 1:100){
    
      # get ex6 sampled data
      ex6.estimated = sample_n(d.goodStim.lab.estimated, n, replace = T)
      
      # bind two data sets together, distinguished by exp value
      d_both = rbind(ex6.estimated, d.goodStim.turk)
      d_both = colwise(as.factor)(d_both)

      # run model and get p value
      m = tidy(glm(w.ans.cat ~ Answer.sample * exp, d_both, family = "binomial"))
      if (dim(m)[1] > 3) {
         ps[s] = m[m$term == "Answer.sampleteacher:expexp6", "p.value"] 
      } else {
         ps[s] = "NA"
      }
  }
  prop_sig_ps[n] = length(which(ps < .05))/length(ps)
}

qplot(1:n, prop_sig_ps, xlab = "n")

# just plot proportions
exp4_5props = prop.table(table(d_both)[,,1],1) %>%
            melt() %>%
            mutate(exp = "Exp. 4 and 5")


both_props = prop.table(table(d_both)[,,2],1) %>%
            melt() %>%
            mutate(exp = "Exp. 6 estimated") %>%
            rbind(exp4_5props)

both_props %>%
  ggplot(aes(x = w.ans.cat, y = value, 
                             fill = Answer.sample)) +
  geom_bar(stat = "identity", 
           position = position_dodge()) +
  facet_grid(. ~ exp) +
  ylim(0, 1) +
  ylab("Prop. Participants") +
  xlab("Generalization Pattern") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", 
                    palette = "Set1") 

# flip learner and teacher to debug
exp4and5.flipped = d_both %>%
                  filter(exp == "exp4and5")%>%
                  mutate(Answer.sample, 
                         Answer.sample = revalue(Answer.sample, 
                                                   c("learner" = "teacher",
                                                     "teacher"= "learner")))

d_both2 = rbind(ex6.estimated, exp4and5.flipped)
exp4_5props = prop.table(table(d_both2)[,,1],1) %>%
            melt() %>%
            mutate(exp = "Exp. 4 and 5")

both_props = prop.table(table(d_both2)[,,2],1) %>%
            melt() %>%
            mutate(exp = "Exp. 6 estimated") %>%
            rbind(exp4_5props)

both_props %>%
  ggplot(aes(x = w.ans.cat, y = value, 
                             fill = Answer.sample)) +
  geom_bar(stat = "identity", 
           position = position_dodge()) +
  facet_grid(. ~ exp) +
  ylim(0, 1) +
  ylab("Prop. Participants") +
  xlab("Generalization Pattern") +
  themeML + 
  scale_fill_brewer(name = "Sampling\nCondition", 
                    palette = "Set1") 

d_both2 = colwise(as.factor)(d_both2)
tidy(glm(w.ans.cat ~ Answer.sample * exp, d_both2, family = "binomial"))

```



```{r, include = F, eval = F}
      #d_both <- colwise(as.factor)(d_both)

sampleTable <- function(Full, n) {
    Frame <- expand.grid(lapply(dim(Full), seq))
    m = table(Frame[sample(1:nrow(Frame), n, prob = Full, replace = TRUE), ])

    # check dimensions
    dim_check = (dim(m) == c(2,2))
    if (all(dim_check)){
        colnames(m) <- colnames(e4_and_5)
        rownames(m) <- rownames(e4_and_5)
    } else if (all(dim_check == FALSE)) {
        missing = setdiff(c("1", "2"), rownames(m))
        shared = intersect(c("1", "2"), rownames(m))
        m = rbind(m, c(0))
        rownames(m)[2] = rownames(e4_and_5)[as.numeric(missing)]
        rownames(m)[1] = rownames(e4_and_5)[as.numeric(shared)]
        missing = setdiff(c("1", "2"), colnames(m))
        shared = intersect(c("1", "2"), colnames(m))
        m = cbind(m, c(0, 0))
        colnames(m)[2] = colnames(e4_and_5)[as.numeric(missing)]
        colnames(m)[1] = colnames(e4_and_5)[as.numeric(shared)]
    } else {
       if (!(dim_check)[1]){
        missing = setdiff(c("1", "2"), rownames(m))
        shared = intersect(c("1", "2"), rownames(m))
        m = rbind(m, c(0, 0))
        rownames(m)[2] = rownames(e4_and_5)[as.numeric(missing)]
        rownames(m)[1] = rownames(e4_and_5)[as.numeric(shared)]
        colnames(m) = colnames(e4_and_5)
      }
      if (!(dim_check)[2]){
        missing = setdiff(c("1", "2"), colnames(m))
        shared = intersect(c("1", "2"), colnames(m))
        m = cbind(m, c(0, 0))
        colnames(m)[2] = colnames(e4_and_5)[as.numeric(missing)]
        colnames(m)[1] = colnames(e4_and_5)[as.numeric(shared)]
        rownames(m) = rownames(e4_and_5)
      }
    }
    
    m <- m[rownames(e4_and_5),colnames(e4_and_5)]
    m
}


# run power simulation
prop_sig_ps = numeric(0)
for (n in seq(1000,10000,1000)){
  print(n)
  ps = numeric(0)
  for (s in 1:10){
      # get ex6 sampled data
      sampled_ex6 = sampleTable(ex6, n)

      # get into long form (each row as an observation)
      sampled_ex6_df <- melt(sampled_ex6,id=c("w.ans.cat"),
                             variable_name = "Answer.sample")
      sampled_ex6_l = data.frame(matrix(NA, 
                                        nrow = sum(sampled_ex6_df$value), 
                                        ncol=2))
      
      #print(sampled_ex6)
      counter = 1
      for (i in 1:4){
        for (j in 1:sampled_ex6_df[i, 3]){
          if ((sampled_ex6_df[i, 3]) > 0) {
            sampled_ex6_l[counter,c(1,2)] = sampled_ex6_df[i, c(1,2)]
            counter = counter + 1
          }
        }
      }
      sampled_ex6_l$X1 = factor(sampled_ex6_l$X1)
      sampled_ex6_l$w.ans.cat = revalue(sampled_ex6_l$X1,  
                                        c("1"= "basic", "2"="sub"))
      sampled_ex6_l$X2 = factor(sampled_ex6_l$X2)
      sampled_ex6_l$Answer.sample = revalue(sampled_ex6_l$X2, 
                                            c("1"="learner", "2"="teacher"))

      sampled_ex6_l$exp = "exp6"
      sampled_ex6_l = sampled_ex6_l[,-c(1,2)]
      d.goodStim.turk$exp = "exp4_and_5"
      
      # bind two data sets together, distinguished by exp value
      d_both = rbind(d.goodStim.turk, sampled_ex6_l)
      
      # run model and get p value
      m = tidy(glm(w.ans.cat ~ Answer.sample * exp, d_both, family = "binomial"))
      if (dim(m)[1] > 3) {
         ps[s] = m[m$term == "Answer.samplelearner:expexp6", "p.value"] 
      } else {
         ps[s] = "NA"
      }
  }
  prop_sig_ps[n] = length(which(ps < .05))/length(ps)
}

ex6.learner.estimated = sample_n(d.goodStim.lab.estimated[
        d.goodStim.lab.estimated$Answer.sample == "learner",], round(n/2), replace = T)
      
      ex6.teacher.estimated = sample_n(d.goodStim.lab.estimated[
        d.goodStim.lab.estimated$Answer.sample == "teacher",], round(n/2), replace = T)
```

Plot "other" responses.
```{r}
response.patterns.t1 = others.t1 %>%
  select(workerids, Answer.sample, c(13,14,21,23)) %>%
  mutate(pattern = paste(Answer.Qwsmm1,  Answer.Qwsmm2, 
                         Answer.Qwsm1, Answer.Qwsm2, sep = "")) %>%
  mutate(pattern_basic = paste(Answer.Qwsmm1,  Answer.Qwsmm2, sep = "")) %>%
  mutate(pattern_basic_null = ifelse(pattern_basic == "00", "no basic, inconsistent sub.", 
                                     "some basic, inconsistent sub.")) %>%
  select(workerids, Answer.sample, pattern, pattern_basic, pattern_basic_null) %>%
  mutate(pattern = as.factor(pattern))

p.other.t1 = ggplot(response.patterns.t1, aes(x = pattern)) + 
  geom_bar(aes(y =..count.., fill = Answer.sample), position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Exp. 1") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position="none") +
  themeML

pattern.sum.t1 = response.patterns.t1 %>%
  group_by(Answer.sample, pattern_basic_null) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n))%>%
  mutate(exp = "Exp. 1")

response.patterns.t2 = others.t2 %>%
  select(workerids, Answer.sample, c(2,3,5,6,7,15,16,17)) %>%
  mutate(pattern = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, Answer.Qsub1, Answer.Qsub2, Answer.Qproper1,
                         Answer.Qproper2, Answer.Qproper3, sep = "")) %>%
  mutate(pattern_basic = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, sep = "")) %>%
  mutate(pattern_basic_null = ifelse(pattern_basic == "000", "no basic, inconsistent sub.", 
                                     "some basic, inconsistent sub.")) %>%
  select(workerids, Answer.sample, pattern, pattern_basic, pattern_basic_null) %>%
  mutate(pattern = as.factor(pattern))

p.other.t2 = ggplot(response.patterns.t2, aes(x = pattern)) + 
  geom_bar(aes(y =..count.., fill = Answer.sample), position = "dodge") +
  ggtitle("Exp. 2") +
  scale_y_continuous(breaks = c(0,2,4,6,8)) + 
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  themeML

pattern.sum.t2 = response.patterns.t2 %>%
  group_by(Answer.sample, pattern_basic_null) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  mutate(exp = "Exp. 2")

response.patterns.l1 = others.l1 %>%
  select(subjno, Answer.sample, c(10,12:15,17:19)) %>%
  mutate(pattern = paste(basic1_a, basic1_b, basic2_a, basic2_b,
                         sub1_a, sub1_b, sub2_a, sub2_b, sep = "")) %>%
    mutate(pattern_basic = paste(basic1_a, basic1_b, basic2_a, basic2_b, sep = "")) %>%
   mutate(pattern_basic_null = ifelse(pattern_basic == "0000", "no basic, inconsistent sub.", 
                                     "some basic, inconsistent sub.")) %>%
  select(subjno, Answer.sample, pattern, pattern_basic, pattern_basic_null) %>%
  mutate(pattern = as.factor(pattern))

p.other.l1 = ggplot(response.patterns.l1, aes(x = pattern)) + 
  geom_bar(aes(y =..count.., fill = Answer.sample), position = "dodge") +
  ggtitle("Exp. 3") +
  scale_y_continuous(breaks = c(0,1,2)) + 
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  themeML

pattern.sum.l1 = response.patterns.l1 %>%
  group_by(Answer.sample, pattern_basic_null) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  mutate(exp = "Exp. 3")

response.patterns.t3 = others.t3 %>%
  select(workerids, Answer.sample, c(18,20:27)) %>%
  mutate(pattern = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, Answer.Qsub1, Answer.Qsub2, Answer.Qproper1,
                         Answer.Qproper2, Answer.Qproper3, sep = "")) %>%
  mutate(pattern_basic = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, sep = "")) %>%
  mutate(pattern_basic_null = ifelse(pattern_basic == "000", "no basic, inconsistent sub.", 
                                     "some basic, inconsistent sub.")) %>%
  select(workerids, Answer.sample, pattern, pattern_basic, pattern_basic_null) %>%
  mutate(pattern = as.factor(pattern))

p.other.t3 = ggplot(response.patterns.t3, aes(x = pattern)) + 
  geom_bar(aes(y =..count.., fill = Answer.sample), position = "dodge") +
  ggtitle("Exp. 4") +
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  themeML

pattern.sum.t3 = response.patterns.t3 %>%
  group_by(Answer.sample, pattern_basic_null) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  mutate(exp = "Exp. 4")


response.patterns.t4 = others.t4 %>%
  select(workerids, Answer.sample, c(18,20:27)) %>%
  mutate(pattern = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, Answer.Qsub1, 
                         Answer.Qsub2, Answer.Qproper1,
                         Answer.Qproper2, Answer.Qproper3, sep = "")) %>%
  mutate(pattern_basic = paste(Answer.Qbasic1,  Answer.Qbasic2, 
                         Answer.Qbasic3, sep = "")) %>%
  mutate(pattern_basic_null = ifelse(pattern_basic == "000", "no basic, inconsistent sub.", 
                                     "some basic, inconsistent sub.")) %>%
  select(workerids, Answer.sample, pattern, pattern_basic, pattern_basic_null) %>%
  mutate(pattern = as.factor(pattern))

p.other.t4 = ggplot(response.patterns.t4, aes(x = pattern)) + 
  geom_bar(aes(y =..count.., fill = Answer.sample), position = "dodge") +
  ggtitle("Exp. 5") +
  #scale_fill_discrete(name="Condition") +
  #theme(legend.position="bottom") +
  #theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  themeML

pattern.sum.t4 = response.patterns.t4 %>%
  group_by(Answer.sample, pattern_basic_null) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  mutate(exp = "Exp. 5")


all.pattern_basic_null = rbind(pattern.sum.t1, pattern.sum.t2, 
                               pattern.sum.l1, pattern.sum.t3, pattern.sum.t4)

#Exp.1: [basic-1, basic-2, sub-1, sub-2]
#Exp. 2, 4 & 5: [basic-1, basic-2, basic-3, sub-1, sub-2, proper-1, proper-2, proper-3]
#Exp. 3: [basic-1a, basic-1b, basic-2a, basic-2b, sub-1a, sub-1b, sub-2a, sub-2b ]


ggplot(all.pattern_basic_null, aes(x = Answer.sample, 
                                   y= prop,
                                   fill = pattern_basic_null)) + 
  geom_bar(stat = "identity", position = "stack") +
  facet_grid(.~exp) +
  scale_fill_discrete(name="") +
  ylab("Prop excluded participants") +
  xlab("Condition") +
  ggtitle("Exclusion patterns") +
  theme(legend.position="bottom") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  themeML



```
