\documentclass[man]{apa2}
\usepackage{pslatex}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{covington}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{booktabs}
\usepackage{setspace}


\title{Understanding the effect of social context on learning: \\ A replication of Xu and Tenenbaum (2007b)}

\twoauthors{Molly L. Lewis}{Michael C. Frank}
\twoaffiliations{Department of Psychology, Stanford University}{Department of Psychology, Stanford University}


\abstract{

~\\

Keywords: word learning, induction, Bayesian inference}

\shorttitle{Replication of Xu and Tenenbaum 2007b}
\rightheader{Replication of Xu and Tenenbaum 2007b}

\acknowledgements{ 

~\\

\noindent Address all correspondence to Molly L. Lewis, Stanford University, Department of Psychology, Jordan Hall, 450 Serra Mall (Bldg. 420), Stanford, CA, 94305. Phone: 650-721-9270. E-mail: \texttt{mll@stanford.edu}}

\begin{document}

\maketitle              


\section{Introduction}
Imagine you were on a hike and saw a rock positioned oddly at an ambiguous intersection of trails.  If you thought you were on a trail  which no one had traveled in years, you probably wouldn't think much of that rock. But, if you knew your  campmate had traveled that same trail earlier that day, you might interpret the rock differently: You might interpret the rock as a sign intended to point you to the correct path. This intuition---that the  source of a piece of information influences the strength of the inference to be drawn---suggests that social information may have a privileged role in human learning.

\citeA{xu2007} examine this phenomenon in the context of a particularly difficult inductive problem: Concept generalization in word learning. Faced with a novel word and its referent, children must decide between an infinite number of hypotheses about the concept extension of that word. For example, consider a child who hears the word  ``banana" in the context of a single banana on a table. While the referent of that object is clear in the moment of language use (i.e., the particular banana on the table), the broader concept is highly ambiguous: ``banana" could refer to the category of bananas, the category of fruit, that particular species of banana (e.g., plantains), yellow things, or any number of other ad-hoc categories. 

\citeA{xu2007} ask whether children make use of the information source of a new word to guide their inferences about how to generalize its meaning. In particular, they test a prediction that falls out of their word learning model. In their Bayesian model, learners observe data as word-object pairs and make inferences about the concept associated with that word from a hypothesis space of all possible meanings. Critically, the model predicts that  an ideal  learner should generalize more broadly when the exemplar is sampled from the full hypothesis space of meanings ({\it weak sampling}), and should generalize more narrowly when the exemplar is sampled from only  the true concept of the word within the full hypothesis space ({\it strong sampling}). 

In their experiment, \citeA{xu2007} manipulate  sampling  ``strength"  through  the presentation source of the data. The learner is either presented with three exemplars of the target word from a knowledgeable teacher or the learner makes (correct) guesses about the referent of the word. Critically, in both conditions, the data that the participants observes is the same:  three exemplars from the same subordinate category. What differs is the strength of the sampling.  Since the teacher  knows the true concept, the data are sampled strongly from the true concept. But, in the learner-generated condition, the learner is naive about the true underlying concept and thus the data are sampled weakly from the full hypothesis space.  The key prediction is that, given a hypothesis space with hierarchical concepts (basic, subordinate, superordinate; i.e., banana, plantain, fruit),  participants in the teacher condition should be more likely to generalize broadly to the basic level, while participants in the learner condition should generalize conservatively to only the subordinate condition. Their data strongly support this prediction in both adults ($d = 1.74\ [.47,\ 3.01]$) and children  ($d = .98\ [.29,\ 1.67]$). % check these


There are a number of reasons to conduct a replication of this study. First, replication attempts of other predictions of this model have challenged this framework. This paper 
\cite{xu2007a}
\cite{spencer2011}
\cite{jenkins2015non}


There are additional reasons to conduct a replication of this particular study. \cite{navarro2012sampling}. More generally, evidence suggests that effects that rely on social manipulations are less likely to replicate than effects in more ``cognitive" domains \cite{reproProj2015}.

Finally, this study is important to replicate because the broad theoretical question---how the source of information influences learning---has far-reaching implications for our understanding of human learning. Every piece of data observed in the world, including the experimental context,  is observed in some social context. While the degree of this social pressure may vary (consider yourself observing flowers  alone in a forest versus a case observing flowers received from your partner on Valentine's day), humans are always part of a social system. Thus, in our effort to understand how learners make inferences on the basis of observations in the world, it is important to understand what factors influence this inference, and the source of these observations is likely an important factor.

The social context of human learning also has practical consequences for the interpretation of data collected in psychological experiments. This is because experimental data are often consistent with at least two accounts---an account that relies on  reasoning about the intention of the experimenter, and an account that relies on context-independent reasoning. Consider two examples. A well-known phenomenon in word learning is that children are biased to select a novel object for a novel word, given the presence of both a familiar and novel object \cite<often referred to as {\it mutual exclusivity} in the literature, >{markman1988}. This pattern is difficult to account for psychologically, however, because there are at least two accounts of this behavior. On the one hand, this result could be due to a context-independent bias to assume that lexicons are structured with one word mapping to one concept, and one concept mapping to one word. Another possibility relies on reasoning about the intentions of the experimenter \cite<Why would the experimenter use a strange word to refer to the familiar object if she meant the familiar one?;>{clark1987principle, clark1988logic}. Both of these accounts make similar predictions, and are therefore difficult to disentangle empirically.

Another example of this interpretative ambiguity is the \citeA{heider1944} study. In this task, participants viewed a short movie showing several geometric shapes moving in a way that appeared to be contingent. Nearly all participants spontaneously interpreted the video as depicting animate  beings, rather than as simple shapes moving around. Like in the case of mutual exclusivity, there are at least two ways to interpret this result. One possibility is that participants rely on low level features of the scene to infer animacy (e.g., contingency), but another possibility is that participants infer the intention of the experimenter who created the videos and assume an animate intention. 

These two cases---mutual exclusivity and animacy projection---represent a sample of a pervasive theoretical issue in experimental psychology: Data consistent with both pragmatically rich  and  context-independent accounts.  There is not a simple solution to this empirical challenge because it is impossible to fully eliminate a social context from experimental paradigms. Our best bet, therefore, is to try to understand the influence of the social context on learning, and  \citeA{xu2007} represents a insightful attempt to systematically shed light on this practical issue.
%, in which participants projected animate qualities onto objectively inanimate stimuli. 

Thus, given the uncertainty associated with  the \citeA{xu2007} result, as well as its theoretical and practical significance, we sought to replicate it.  We conducted four replications of \citeA{xu2007}, three online (Exp. 1, 2, and 4) and one in-person (Exp. 3).  Our data replicate the original effect, but suggest an effect much smaller in magnitude than the original report. In the General Discussion, we suggest a number of factors that may influence the magnitude of this effect that should be explored in future work.

%Given the relevance of this broader question, therefore, this study explores a domain that is particularly important to gain theoretical clarity. 

%All experimental data---and simply data more generally---is collected in a social context. 
%Difficult to interpret -- Hieder, ME -- because the inferences that are drawn are consistent with both a pragmatic inference as well as a context-independent inference. It is therefore important --- both for our understanding of how to interpret experimental results, as well as for our understanding of human learning more generally --- to understand how the source of information about the world influences learning.  The target study provides a key contribution to this question by directly manipulating the source of learners' data and asking how that influences learning.


%Both of the scenarios described above illustrate a property of human communicative behavior: Any act of communication is supported both by our context-dependent, pragmatic abilities and communicative biases encoded in the structure of language. To understand the psychological basis of these behaviors, we must disentangle these supports empirically. In this paper, we explore the nature of this empirical challenge, the evidence for its existence in each of the case studies we described, and a potential way forward.




  
\section{Experiment 1} 
In Experiment 1, we attempted to replicate the original design in an online paradigm. 

\subsection{Methods}
\subsubsection{Participants} 
The original sample with adults included 14 participants. We recruited 296[not sure how to justify this number] adult participants online through Amazon Mechanical Turk. Participants were paid US \$0.25. 
\subsubsection{Stimuli}
We created four sets of objects similar to the original  stimuli(Figure \ref{fig:stims}, left)\footnote{All stimuli, experiments, raw data and analysis code can be found at \url{XX}.}. There were four basic level categories that included 15 unique objects each. Within each basic-level category, there were three subordinate categories, with 5 unique objects each. The same novel words were used as the original: ``wug", ``tupa," ``blicket" and ``fep."
\begin{figure}[t]
 \begin{center} 
  \includegraphics[width=5in]{figures/stims.png} 
  \caption{ \label{fig:stims} Sample stimuli used in Experiments 1-3 (left) and Experiment 4 (right). The Experiment 4 stimuli are intended to be maximally similar to the original Xu and Tenenbaum (2007b) stimuli, with lower subordinate-level variability than the stimuli used in Experiments 1-3. The full set of stimuli can be accessed here: xx. 
 } 
 \end{center} 
\end{figure}	
 
\subsubsection{Procedure}
 \begin{figure} [t]
 \begin{center} 
  \includegraphics[width=5.5in]{figures/screen.png} 
  \caption{\label{fig:screen} Screen shots of the training (left) and testing (right) phases in Experiment 1. } 
 \end{center} 
\end{figure}


Participants first viewed an instruction page that described the task. In the teacher condition, the instructions read: 
\begin{quote}
In the first part of the experiment, you will see pictures of objects. Some of the objects are called  \textit{wugs}. In order for you to learn which objects are  \textit{wugs}, I will circle three of them for you. After you learn about the  \textit{wugs}, you will be asked questions about them.
\end{quote}
In the learner condition, the instruction were identical except the second sentence above was replaced with: ``In order for you to learn which objects are  \textit{wugs} you will try to find two of them. I will tell you whether you are right or wrong."

Participants then viewed a screen showing all the objects from two basic level categories. Within each basic-level category, the shapes were arranged in a 5 x 3 grid, and the two categories were spatially separated (Figure \ref{fig:screen}). One of the objects in the category presented on the left  was circled. In the teacher condition, the instructions read: ``Find the object that is circled below. That object is a \textit{wug}. When you click on the `See Another' button, I will show you another \textit{wug}.'' The participant  was then asked to press a button which caused a circle to appear around one of the exemplars from the same subordinate category as the initially circled object. The participant clicked the button twice in total. 

In the learner condition, the instructions were identical, except the last sentence was replaced with: ``The object circled below is a \textit{wug}.  Click on two more \textit{wugs}." Participants were then asked to click on two more objects. After each click, a pop-up window appeared with the text ``You're correct! That's a wug." This text appeared regardless of which object the participant clicked on. The display then showed the object with a circle around it to indicate that it had been selected. Critically, in both the teacher and the learner conditions, the final display was identical: Thirty objects from two basic level categories, with three circled exemplars.

Participants then advanced to the test phase. On the test screen, the objects from the training phase were shown at the top of the page in an identical format to the training phase, but without the exemplars circled. Below these objects was a horizontal line, and a generalization question (Figure \ref{fig:screen}). There were five generalization questions presented sequentially in the same order as in the original report (subordinate match, basic non-match, basic match, subordinate match, basic match). In each test question, one of the exemplars is shown with the following text above: ``Look at the object below. Is this a wug?" Participants  responded by marking a ``yes" or ``no" radio button.  [then we asked some other questions about a new category -- is it necessary to describe this?]

Finally, we asked an attention check question where participants had to recall the label they learned about from four alternatives.

Objects categories and word items were randomized across participants. The order of presentation of the individual objects on the screen was also randomized, as was the placement of the first circle. Sampling condition was manipulated between-participants.  This and all subsequent online paradigms can be viewed directly here: \url{https://mllewis.github.io/projects/xtSamp/xtSampindex.html}.

\subsection{Results and Discussion}
 \begin{figure} [t]
 \begin{center} 
  \includegraphics[width=6.5in]{figures/FIG_2.pdf} 
  \caption{\label{fig:bar_plots} Proportion participants generalizing to the subordinate (sub.) or basic level category in the original adult experiment ($N = 14$) and in our four replication attempts ($N_{1} = 296$; $N_{2} = 14$; $N_{3}  = 14$; $N_{4}  = 14$).  Experiments 1, 2, and 4 were conducted online, and Experiment 3 was conducted in-person. Proportions shown here are determined based on liberal criteria, described in the Main Text. Error bars reflect 95\% confidence intervals, calculated via non-parametric bootstrapping. Note that we obtained the error bars for our replications by aggregating across participants, but the error bars in the original reflect aggregation across trials (2 per participant). Our error bars are a more conservative estimate of variance. } 
 \end{center} 
\end{figure}

We excluded participants from our analysis who responded ``yes" to the basic non-match question ($N=8$) or who did not select subordinate matches in the learning condition ($N = 21$). No participant missed the attention check question. Our final sample thus included 274 participants ($N_{learner} = 128$; $N_{teacher} = 146$).

In all four experiments, we adopt two different criteria for categorizing participants' response pattern. Unlike in the original report, we found that not all participants responded consistently across questions of the same type within a trial (for example, a participant might respond ``yes" to one subordinate match and ``no" to another). Thus, we adopted a liberal criteria which categorized a participant as a basic-level generalizer if they responded ``yes" to both the subordinate matches and {\it at least one} basic-level match. Under our strict criteria, a participant was categorized as a basic-level generalizer if they responded ``yes" to both the subordinate matches and {\it both} basic-level matches.  Under both criteria, a participant was categorized as a subordinate-level generalizer if they responded ``yes" to only the subordinate level matches.  We excluded participants from our analysis who could be categorized under the criteria.

Under the liberal criteria, 79 participants could not be categorized as either basic or subordinate-level generalizers, and thus were excluded. While the   responses followed same qualitative pattern the original, the difference  between sampling conditions was not reliable ($\chi^2(1) = 0.63$,  $p = .42$,  $d = XXX [XX,\ XX]$; Figure \ref{fig:bar_plots}).

Under the strict criteria,





 \begin{figure} [t]
  \includegraphics[width=3in]{figures/FIG_3.pdf} 
  \caption{\label{fig:effect_sizes} Effect size for the original experiment with adults, and our four replication attempts.  Effect sizes were calculated using the log odds ratio (S\'{a}nchez-Meca, Mar\'{i}n-Mart\'{i}nez, \& Chac\'{o}n-Moscoso, 2003). Those shown here reflect the liberal generalization criteria described in the Main Text. Errors bars are 95\% confidence intervals. Note that we obtained the error bars for our replications by aggregating across participants, but the error bars in the original reflect aggregation across trials (2 per participant). Our error bars are a more conservative estimate of variance. } 
\end{figure}




\section{Experiment 2}

\subsection{Methods}

\subsubsection{Participants} 
\subsubsection{Stimuli}



\subsubsection{Procedure}

\subsection{Results and Discussion}

\subsection{Conclusion}



\section{Experiment 3}
* notable flip
\subsection{Methods}

\subsubsection{Participants} 
\subsubsection{Stimuli}


\subsubsection{Procedure}

\subsection{Results and Discussion}

\section{Experiment 4}


\subsection{Methods}

\subsubsection{Participants}  paid 30 cents
\subsubsection{Stimuli}


\subsubsection{Procedure}

\subsection{Results and Discussion}

\subsection{General Discussion}
* in the learner condition, only in lab shows same pattern as original in sub vs. basic
The most striking thing about this result is not the fact that we replicated it, but how much smaller the effect is than the original, and how sensitive it is to other factors

- would be nice to have paradigm where sampling didn't come from learner in learning context (other random way)
- vary variability parametrically
- things that might matter:
* variability visually
* spatial structure
* feature of the teacher (reliable?)
* cost of getting it wrong ("good enough processing" - in communiation vs. turk)

\nocite{sanchez2003effect}

\bibliographystyle{apacite2}
\bibliography{biblibrary}

\newpage
\theappendix 
\end{document}
